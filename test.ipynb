{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import Chroma \n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from pathlib import Path\n",
    "from chromadb.utils import embedding_functions\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "import gradio as gr\n",
    "import re\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma( \n",
    "    embedding_function = OpenAIEmbeddings(model=\"text-embedding-3-large\"),\n",
    "    collection_name=\"asrin-getirdigi-tereddutler\", \n",
    "    persist_directory=\"./.chromadb\",\n",
    "    collection_metadata={\"embeeding_model\":\"text-embedding-3-large\",\n",
    "    \"chunk_size\":1024,\n",
    "    \"chunk_overlap\":100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(query: str, vectorstore) ->list:\n",
    "    results = vectorstore.similarity_search_with_score(\n",
    "    query, k=3)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_response(query: str, retrieved_docs):\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\",temperature=0) \n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "    result = {\"query\": query, \"retrieved_docs\": retrieved_docs, \"response\": None}\n",
    "    generation_chain = prompt | llm | StrOutputParser()\n",
    "    result[\"response\"] = generation_chain.invoke({\"context\": retrieved_docs, \"question\": query})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_meaningful_input(user_input: str) -> bool:\n",
    "    \"\"\"\n",
    "    Kullanıcıdan gelen inputun anlamlı olup olmadığını kontrol eder.\n",
    "    \n",
    "    Args:\n",
    "        user_input (str): Kullanıcıdan gelen metin.\n",
    "    \n",
    "    Returns:\n",
    "        bool: Anlamlı ise True, değilse False.\n",
    "    \"\"\"\n",
    "    # Boş veya sadece boşluklardan oluşuyorsa False döndür\n",
    "    if not user_input.strip():\n",
    "        return False\n",
    "    \n",
    "    # Sadece semboller veya rastgele karakterler varsa False döndür\n",
    "    # Alfanümerik (harf veya rakam) karakterlerin olup olmadığını kontrol eder\n",
    "    if not re.search(r'[a-zA-Z0-9]', user_input):\n",
    "        return False\n",
    "    \n",
    "    # Özel bir uzunluk kontrolü (ör. en az 3 karakter anlamlıdır)\n",
    "    if len(user_input.strip()) < 3:\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context(result):\n",
    "    contexts =\"\"\n",
    "    for r in result:\n",
    "        contexts +=r[0].page_content\n",
    "    return contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectordb():\n",
    "    vectorstore = Chroma( \n",
    "    embedding_function = OpenAIEmbeddings(model=\"text-embedding-3-large\"),\n",
    "    collection_name=\"asrin-getirdigi-tereddutler\", \n",
    "    persist_directory=\"./.chromadb\",\n",
    "    collection_metadata={\"embeeding_model\":\"text-embedding-3-large\",\n",
    "    \"chunk_size\":1024,\n",
    "    \"chunk_overlap\":100})\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"Allah her şeyi yarattı, -hâşâ- O’nu kim yarattı?\"\n",
    "query2 =\"Nürnbergde hava nasil?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allah, varlığı kendinden olan ve yaratılmamış tek varlıktır. Yaratılan her şey muhtaç ve sonradan var olmuştur. Bu nedenle, \"O'nu kim yarattı?\" sorusu, yanlış bir anlayışın sonucudur.\n"
     ]
    }
   ],
   "source": [
    "retrieved_docs = []\n",
    "if is_meaningful_input(message):\n",
    "    retrieved_docs = get_context(message, get_vectordb())\n",
    "    if retrieved_docs[0][1]>1:\n",
    "        print(\"Sormus oldugunuz soru HocaGPT nin kapsami disinda oldugundan cevap veremiyorum. Lütfen konu ile ilgili bir soru sormayi deneyin.\")\n",
    "    else:\n",
    "        context = create_context(retrieved_docs)\n",
    "        gpt_response = generate_response(message, context)\n",
    "        print(gpt_response['response'])\n",
    "else:\n",
    "    print(\"Lütfen anlamlı bir soru sorunuz.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Document türündeki verileri JSON'a dönüştür\n",
    "def document_to_dict(documents):\n",
    "    dict_list = []\n",
    "    for doc in documents:\n",
    "        doc_dict ={ \"id\": None, \"metadata\": None, \"page_content\": None,\"relevance_score\": None}\n",
    "        \n",
    "        doc_dict['id']=doc[0].id\n",
    "        doc_dict['metadata']=doc[0].page_content\n",
    "        doc_dict['page_content']=doc[0].metadata\n",
    "        doc_dict['relevance_score']=doc[1]\n",
    "        dict_list.append(doc_dict)\n",
    "    return dict_list\n",
    "        \n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "history = {\"id\":None,\"retrieved_docs\": None, \"gpt_response\": None, \"message\": None, \"zeitstempel\": None}\n",
    "retrieved_docs = document_to_dict(retrieved_docs)\n",
    "history['retrieved_docs']= retrieved_docs\n",
    "history['response']=gpt_response['response']\n",
    "history['message']=message\n",
    "history['zeitstempel']=datetime.now().isoformat()\n",
    "history['id']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['retrieved_docs', 'gpt_response', 'message', 'zeitstempel', 'response'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = document_to_dict(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "try:\n",
    "    with open('chat_histroy.json', 'r') as datei:\n",
    "        json_data = json.load(datei)\n",
    "except Exception as errror:\n",
    "    print(f'errror: {errror}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"ad\": \"Ahmet\",\n",
    "    \"yas\": 25,\n",
    "    \"sehir\": \"İstanbulwer\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"chat_histroy.json\", \"w\") as json_file:\n",
    "        json.dump(json_data, json_file, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
